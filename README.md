# ShadowDancer
Artist Statement
As an individual who is a passionate dancer, artist and programmer, I always wanted to mix the dance with some level of digital arts. Without the use of any professional hardware but a recordable laptop, it could get hard and frustrating sometimes while testing and adjusting the piece, but art is always fun, and I finally managed to interact with my Shadow Dancer while dancing.
Formal Qualities
This piece is formed by two modes, the shadow mode, and the dark mode. In the shadow mode, the filter is black and white, and most importantly, one can move their body parts in certain ways to trigger certain effects accordingly. For example, if one moves both arms to the top right, a knife will show up at approximately one’s heart; if one moves right arm up and left arm down, the voice of me shouting “no” will be played; if one open up their arms from the middle to the bottom, the gun shooting animation will show up; and if one put both arms down, the dark mode will be triggered. In the dark mode, there are only the color black and the color white. As one move in front of the camera, some part of the frame’s color will change, and the different part will become in the color of white; while the part with the same color will be in the color of black. This creates very cool looking effects especially when someone does big moves. Also, if one tries to hold your hand on the left or right, one will be able to support either fireballs, water balls or lightning balls, and the balls will finally disappear with the fade of one’s hands.
Context
This art piece is created in 2020, where street dancing is growing and the Electronic Dance Music (EDM) is becoming increasingly popular. With the rapid development of the Internet and augmented reality technologies, lots of dance videos are being processed by adding all different kinds of effects to make the dance richer. As a dancer who is inspired by such technologies, I wonder the possibility of displaying the result of processing the dance in real-time with the most basic equipment.

Augmented Reality dance done by processing the recorded video
Technical Description
This art piece is being implemented in processing. To pre-process all the audios we need, GarageBand is also being used. 
Code Structure and Flow
The implementation of this piece includes the use of library Optical Flow and library OpenCV. By making use of the optical flow library, we can now determine the direction and amplitude of all the vectors within the screen. In this case, we divide the screen into two parts from the middle, then by summing all the vectors up, we can get two PVectors including the left screen’s vector and the right screen’s. Since we can control our dance moves, we can now achieve different effects when detecting the values of these two PVectors. By using the OpenCV library, we can now differentiate the moving area within the camera. By calculating the space of these connected area, we ignore the small ones and catch the big ones. Again, since we can control our dance movement, we can now assume these areas are caused by the movements of our arms and hands, and we can focus on these areas and add effects upon that.
Key Aspect 
There are many things need to pay attention in this piece. First of all, we need to set a timer to stop detecting all the changes on the screen to stop the shadow mode and dark mode from switching back and forth. Each effect also requires a timer to keep the effect steady. To make good use of the optical flow, we need to use both the PVectors and the normalized PVectors. At first, I did not initialize the normalized PVectors since they will consider only direction, which means that no matter how small the movement is, a PVector could potentially have huge value on x or y. However, sometimes the value of default PVector is not sensitive enough to get the correct values of x and y; especially when using a low-quality camera to record high speed movements, the result vectors could be off. Therefore, by using the normalized PVector and set the limit close to 1, it can now determine the direction of the movements. Another tricky part is that many conditions have similar constrains, values of limitations must be adjusted according to the background, lighting and clothing carefully. Last but not least, in the dark mode, to avoid the computer recognize one’s body in the middle as hands, the detected area excludes the middle 600px horizontally so that it would only consider where the hands are supposed to be moving. 

